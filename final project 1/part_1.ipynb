{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Python codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from statistics import mode\n",
    "from numpy import median\n",
    "from sklearn.decomposition import PCA\n",
    "# import tensorflow and keras for autoencoder neural net work\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.76 s, sys: 968 ms, total: 5.72 s\n",
      "Wall time: 5.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mydata=pd.read_csv('NY property data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "The data cleaning process was carried out for all the relevant variables that help describe the valuation, area and location of the property.\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "The process entailed filling missiing values in such a way that it ensures the new values are as close to the actual values as possible and they do not trigger an alarm ini our models as outliers. The process, therefore, was mainly carried out by aggregating all the entries over relevant variables and then filling the missing value by the `median/average/most frequent values` of the missing field within the aggregate that matches with the relevant variables of the given entry.<br> A detailed description of the variables identified and the process to fill in these missing values has been given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new function to calculate the most frequent value, because the built-in function cann't solve a tie.\n",
    "def mods(i):\n",
    "    d = {}\n",
    "    for x in i:\n",
    "        d[x] = d.get(x, 0) +1\n",
    "   \n",
    "    return max(d, key = lambda k: d[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before fill in, we need to get modes for each aggregate/group\n",
    "# Incase there are insufficient entries in each group\n",
    "# We prepared a back-up table which is aggregated by one less category\n",
    "\n",
    "# First, aggregate the records using the Borough, BLOCK, TAXCLASS and compute the mode of the Zip code field\n",
    "d1=mydata[['ZIP','B','BLOCK','TAXCLASS']]\n",
    "count=d1.groupby(['B','TAXCLASS','BLOCK']).agg({'ZIP':[mods, 'count']})\n",
    "\n",
    "# Drop one category and aggregate again to get a higher overall frequency.\n",
    "count2=d1.groupby(['B','TAXCLASS']).agg({'ZIP':[mods, 'count']})\n",
    "\n",
    "# Mode for all ZIP\n",
    "m = mode(mydata['ZIP'])\n",
    "\n",
    "# When there are multiple levels in column names, merge first and second level\n",
    "# count.columns = list(map(''.join, count.columns.values))\n",
    "\n",
    "# Delete the first level in column names\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "\n",
    "# Merge tables to mydata\n",
    "mydata=mydata.merge(count, on = ['B', 'BLOCK','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['B','TAXCLASS'],suffixes = ['','_wide'])  # suffix columns in second table\n",
    "\n",
    "mydata = mydata.rename(columns = {\"mods\":\"mode\",'mods_wide':'widemode','count_wide':'widecount'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Impute missing ZIP values__<br>\n",
    "The rule is : If the group size is greater than 10 records, then use mode in that group, or if less than 10, use mode obtained by aggregating Borough and TAXCLASS. If the number of records in that new group does not exist, use mode by aggregating just TAXCLASS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 1.22 s, total: 23.3 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def compare(x):\n",
    "    \n",
    "    if x['present']:\n",
    "     #   print(2)\n",
    "        if int(x['count'])>= 10:\n",
    "            return x['mode']\n",
    "        \n",
    "        elif int(x['widecount']) >= 10 and (not np.isnan(x['widemode'])):\n",
    "            return x['widemode']\n",
    "        else:\n",
    "            return m\n",
    "    return x['ZIP']\n",
    "\n",
    "# Impute missing values in ZIP\n",
    "mydata['present'] = mydata['ZIP'].isna()\n",
    "mydata['ZIPS']  = mydata.apply(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ZIPS]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "mydata[np.isnan(mydata['ZIPS'])][['ZIPS']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['ZIP'] = mydata['ZIPS'].apply(lambda x: str(int(x)))\n",
    "mydata['ZIP3'] = mydata['ZIP'].apply(lambda x: x[:3])\n",
    "mydata['ZIP4'] = mydata['ZIP'].apply(lambda x: x[:4])\n",
    "\n",
    "# Keep useful columns \n",
    "# ['RECORD', 'B', 'TAXCLASS', 'LTFRONT', 'LTDEPTH', 'STORIES', 'FULLVAL', \n",
    "# 'AVLAND', 'AVTOT', 'ZIP', 'BLDFRONT', 'BLDDEPTH', 'ZIP3', 'ZIP4']\n",
    "\n",
    "for x in ['BBLE','BLOCK', 'ZIPS','LOT', 'EASEMENT','OWNER','BLDGCL','EXT','EXLAND',\n",
    "          'EXTOT','EXCD1','STADDR','EXMPTCL','AVLAND2', 'AVTOT2', 'EXLAND2','EXTOT2',\n",
    "          'EXCD2','PERIOD','YEAR','VALTYPE','mode','count','widemode','widecount','present']:\n",
    "    del mydata[x] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new function getting median even though NA exists.\n",
    "def median_rm_na(x):\n",
    "    l=[]\n",
    "    for i in x:\n",
    "        if i!=0 and np.isnan(i)==False:\n",
    "            l.append(float(i))\n",
    "    return np.median(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Similar rules as we get modes\n",
    "d2=mydata[['TAXCLASS','ZIP','STORIES']]\n",
    "count=d2.groupby(['ZIP','TAXCLASS']).agg({'STORIES':[median_rm_na, 'count']})\n",
    "count2=d2.groupby(['TAXCLASS']).agg({'STORIES':[median_rm_na, 'count']})\n",
    "\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "\n",
    "\n",
    "mydata = mydata.merge(count, on = ['ZIP','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['TAXCLASS'],suffixes = ['', '_wide'])\n",
    "mydata = mydata.rename(columns = {\"median_rm_na\":\"median\",'median_rm_na_wide':'widemedian','count_wide':'widecount'}) \n",
    "m = mydata['STORIES'].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(x):\n",
    "    \n",
    "    if x['present']:\n",
    "        if int(x['count'])>= 10:\n",
    "            return x['median']\n",
    "        elif int(x['widecount'])>=10 and (not np.isnan(x['widemedian'])):\n",
    "            return x['widemedian']\n",
    "        else:\n",
    "            return m\n",
    "    return x['STORIES']\n",
    "\n",
    "mydata['present'] = mydata['STORIES'].isna()\n",
    "mydata['STORY']  = mydata.apply(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [STORY]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[np.isnan(mydata['STORY'])][['STORY']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['STORIES']=mydata['STORY']\n",
    "\n",
    "for x in ['median', 'count', 'widemedian', 'widecount', 'present', 'STORY']:\n",
    "    del mydata[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FullVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.4 s, sys: 1.51 s, total: 42.9 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "d3=mydata[['TAXCLASS','ZIP','ZIP3','FULLVAL']]\n",
    "count=d3.groupby(['ZIP','TAXCLASS']).agg({'FULLVAL':[median_rm_na, 'count']})\n",
    "count2=d3.groupby(['ZIP3','TAXCLASS']).agg({'FULLVAL':[median_rm_na,'count']})\n",
    "# After groupping by zip3 and taxclass, there are some groups have less than 5 records and the median is NaN\n",
    "# Thus, group by taxclass only to avoid NaN\n",
    "count3=d3.groupby(['TAXCLASS']).agg({'FULLVAL':[median_rm_na,'count']})\n",
    "\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "count3.columns=count3.columns.droplevel()\n",
    "m=mydata['FULLVAL'].median()\n",
    "\n",
    "mydata = mydata.merge(count, on = ['ZIP','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['ZIP3','TAXCLASS'],suffixes = ['', '_wide'])\n",
    "mydata = mydata.merge(count3, on = ['TAXCLASS'],suffixes= ['','_wider'])\n",
    "\n",
    "mydata=mydata.rename(columns={'median_rm_na':'median','median_rm_na_wide':'widemedian',\n",
    "                'median_rm_na_wider':'widermedian','count_wide':'widecount','count_wider':'widercount'})\n",
    "\n",
    "\n",
    "# new function to impute missing values\n",
    "def compare(x):\n",
    "    \n",
    "    if (x['present']==True) or (float(x['FULLVAL'])==0):\n",
    "     #   print(2)\n",
    "        if int(x['count'])>= 10 and (not np.isnan(x['median'])):\n",
    "            return x['median']\n",
    "        elif int(x['widecount'])>=10 and (not np.isnan(x['widemedian'])):\n",
    "            return x['widemedian']\n",
    "        elif int(x['widercount'])>=10 and (not np.isnan(x['widermedian'])):\n",
    "            return x['widermedian']\n",
    "        else:\n",
    "            return m\n",
    "    return x['FULLVAL']\n",
    "mydata['present'] = mydata['FULLVAL'].isna()\n",
    "mydata['FULLVAL2']  = mydata.apply(compare, axis = 1)\n",
    "mydata[np.isnan(mydata['FULLVAL2'])][['FULLVAL2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['FULLVAL']=mydata['FULLVAL2']\n",
    "for x in ['median', 'count', 'widecount','widercount','widemedian', 'widermedian', 'present','FULLVAL2']:\n",
    "    del mydata[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVLAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4=mydata[['TAXCLASS','ZIP','ZIP3','AVLAND']]\n",
    "count=d4.groupby(['ZIP','TAXCLASS']).agg({'AVLAND':[median_rm_na, 'count']})\n",
    "count2=d4.groupby(['ZIP3','TAXCLASS']).agg({'AVLAND':[median_rm_na,'count']})\n",
    "# After groupping by zip3 and taxclass, there are some groups have less than 5 records and the median is NaN\n",
    "# Thus, group by taxclass only to avoid NaN\n",
    "count3=d4.groupby(['TAXCLASS']).agg({'AVLAND':[median_rm_na,'count']})\n",
    "\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "count3.columns=count3.columns.droplevel()\n",
    "m=mydata['AVLAND'].median()\n",
    "mydata = mydata.merge(count, on = ['ZIP','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['ZIP3','TAXCLASS'],suffixes = ['', '_wide'])\n",
    "mydata = mydata.merge(count3, on = ['TAXCLASS'],suffixes = ['','_wider'])\n",
    "\n",
    "mydata=mydata.rename(columns={'median_rm_na':'median','median_rm_na_wide':'widemedian',\n",
    "                'median_rm_na_wider':'widermedian','count_wide':'widecount','count_wider':'widercount'})\n",
    "\n",
    "def compare(x):\n",
    "    \n",
    "    if (x['present']==True) or (float(x['AVLAND'])==0):\n",
    "     #   print(2)\n",
    "        if int(x['count'])>= 10 and (not np.isnan(x['median'])):\n",
    "            return x['median']\n",
    "        elif int(x['widecount'])>=10 and (not np.isnan(x['widemedian'])):\n",
    "            return x['widemedian']\n",
    "        elif int(x['widercount'])>=10 and (not np.isnan(x['widermedian'])):\n",
    "            return x['widermedian']\n",
    "        else:\n",
    "            return m\n",
    "    return x['AVLAND']\n",
    "\n",
    "mydata['present'] = mydata['AVLAND'].isna()\n",
    "\n",
    "mydata['AVLAND2']  = mydata.apply(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVLAND2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AVLAND2]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[np.isnan(mydata['AVLAND2'])][['AVLAND2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['AVLAND']=mydata['AVLAND2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [ 'median', 'count','widecount','widercount', 'widemedian', 'widermedian', 'present', 'AVLAND2']:\n",
    "    del mydata[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVTOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d5=mydata[['TAXCLASS','ZIP','ZIP3','AVTOT']]\n",
    "count=d5.groupby(['ZIP','TAXCLASS']).agg({'AVTOT':[median_rm_na, 'count']})\n",
    "count2=d5.groupby(['ZIP3','TAXCLASS']).agg({'AVTOT':[median_rm_na,'count']})\n",
    "# After groupping by zip3 and taxclass, there are some groups have less than 5 records and the median is NaN\n",
    "# Thus, group by taxclass only to avoid NaN\n",
    "count3=d5.groupby(['TAXCLASS']).agg({'AVTOT':[median_rm_na,'count']})\n",
    "\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "count3.columns=count3.columns.droplevel()\n",
    "m=mydata['AVLAND'].median()\n",
    "mydata = mydata.merge(count, on = ['ZIP','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['ZIP3','TAXCLASS'],suffixes = ['', '_wide'])\n",
    "mydata = mydata.merge(count3, on = ['TAXCLASS'],suffixes = ['','_wider'])\n",
    "\n",
    "mydata=mydata.rename(columns={'median_rm_na':'median','median_rm_na_wide':'widemedian',\n",
    "                'median_rm_na_wider':'widermedian','count_wide':'widecount','count_wider':'widercount'})\n",
    "\n",
    "\n",
    "def compare(x):\n",
    "    \n",
    "    if (x['present']==True) or (float(x['AVTOT'])==0):\n",
    "     #   print(2)\n",
    "        if int(x['count'])>= 10 and (not np.isnan(x['median'])):\n",
    "            return x['median']\n",
    "        elif not np.isnan(x['widermedian']):\n",
    "            return x['widermedian']\n",
    "        elif not np.isnan(x['widestmedian']):\n",
    "            return x['widestmedian']\n",
    "        else:\n",
    "            return m\n",
    "    return x['AVTOT']\n",
    "\n",
    "mydata['present'] = mydata['AVTOT'].isna()\n",
    "mydata['AVTOT2']  = mydata.apply(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVTOT2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AVTOT2]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[np.isnan(mydata['AVTOT2'])][['AVTOT2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['AVTOT']=mydata['AVTOT2']\n",
    "for x in [ 'median', 'count', 'widecount','widercount','widemedian', 'widermedian', 'present', 'AVTOT2']:\n",
    "    del mydata[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTFRONT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d6=mydata[['TAXCLASS','ZIP','B','LTFRONT']]\n",
    "count=d6.groupby(['ZIP','TAXCLASS']).agg({'LTFRONT':[median_rm_na, 'count']})\n",
    "count2=d6.groupby(['B','TAXCLASS']).agg({'LTFRONT':[median_rm_na,'count']})\n",
    "\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "mydata = mydata.merge(count, on = ['ZIP','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['B','TAXCLASS'],suffixes = ['', '_wide'])\n",
    "m=mydata['LTFRONT'].median()\n",
    "\n",
    "mydata=mydata.rename(columns={'median_rm_na':'median','median_rm_na_wide':'widemedian','count_wide':'widecount'})\n",
    "\n",
    "def compare(x):\n",
    "    \n",
    "    if (x['present']==True) or (float(x['LTFRONT'])==0):\n",
    "     #   print(2)\n",
    "        if int(x['count'])>= 20 and (not np.isnan(x['median'])):\n",
    "            return x['median']\n",
    "        elif not np.isnan(x['widemedian']):\n",
    "            return x['widemedian']\n",
    "        else:\n",
    "            return m\n",
    "    return x['LTFRONT']\n",
    "\n",
    "mydata['present'] = mydata['LTFRONT'].isna()\n",
    "mydata['LTFRONT2']  = mydata.apply(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LTFRONT2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [LTFRONT2]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "mydata[np.isnan(mydata['LTFRONT2'])][['LTFRONT2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['LTFRONT']=mydata['LTFRONT2']\n",
    "for x in [ 'median', 'count', 'widemedian', 'widecount','present', 'LTFRONT2']:\n",
    "    del mydata[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTDEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d7=mydata[['TAXCLASS','ZIP','B','LTDEPTH']]\n",
    "count=d7.groupby(['ZIP','TAXCLASS']).agg({'LTDEPTH':[median_rm_na, 'count']})\n",
    "count2=d7.groupby(['B','TAXCLASS']).agg({'LTDEPTH':[median_rm_na,'count']})\n",
    "\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "mydata = mydata.merge(count, on = ['ZIP','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['B','TAXCLASS'],suffixes = ['', '_wide'])\n",
    "m=mydata['LTDEPTH'].median()\n",
    "\n",
    "mydata=mydata.rename(columns={'median_rm_na':'median','median_rm_na_wide':'widemedian','count_wide':'widecount'})\n",
    "\n",
    "\n",
    "def compare(x):\n",
    "    \n",
    "    if (x['present']==True) or (float(x['LTDEPTH'])==0):\n",
    "     #   print(2)\n",
    "        if int(x['count'])>= 20 and (not np.isnan(x['median'])):\n",
    "            return x['median']\n",
    "        elif not np.isnan(x['widemedian']):\n",
    "            return x['widemedian']\n",
    "        else:\n",
    "            return m\n",
    "    return x['LTDEPTH']\n",
    "\n",
    "mydata['present'] = mydata['LTDEPTH'].isna()\n",
    "mydata['LTDEPTH2']  = mydata.apply(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LTDEPTH2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [LTDEPTH2]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "mydata[np.isnan(mydata['LTDEPTH2'])][['LTDEPTH2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORD</th>\n",
       "      <th>B</th>\n",
       "      <th>TAXCLASS</th>\n",
       "      <th>LTFRONT</th>\n",
       "      <th>LTDEPTH</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>FULLVAL</th>\n",
       "      <th>AVLAND</th>\n",
       "      <th>AVTOT</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>BLDFRONT</th>\n",
       "      <th>BLDDEPTH</th>\n",
       "      <th>ZIP3</th>\n",
       "      <th>ZIP4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>21400000.0</td>\n",
       "      <td>4225500.0</td>\n",
       "      <td>9630000.0</td>\n",
       "      <td>10004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>193800000.0</td>\n",
       "      <td>14310000.0</td>\n",
       "      <td>87210000.0</td>\n",
       "      <td>10004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>709.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104686000.0</td>\n",
       "      <td>39008700.0</td>\n",
       "      <td>47108700.0</td>\n",
       "      <td>10004</td>\n",
       "      <td>709</td>\n",
       "      <td>564</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>793.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39200000.0</td>\n",
       "      <td>15255000.0</td>\n",
       "      <td>17640000.0</td>\n",
       "      <td>10004</td>\n",
       "      <td>85</td>\n",
       "      <td>551</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>272300000.0</td>\n",
       "      <td>121050000.0</td>\n",
       "      <td>122535000.0</td>\n",
       "      <td>10004</td>\n",
       "      <td>89</td>\n",
       "      <td>57</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RECORD  B TAXCLASS  LTFRONT  LTDEPTH  STORIES      FULLVAL       AVLAND  \\\n",
       "0       1  1        4    500.0   1046.0     50.0   21400000.0    4225500.0   \n",
       "1       2  1        4     27.0    207.0     50.0  193800000.0   14310000.0   \n",
       "2       3  1        4    709.0    564.0      3.0  104686000.0   39008700.0   \n",
       "3       4  1        4    793.0    551.0      2.0   39200000.0   15255000.0   \n",
       "4       5  1        4    323.0   1260.0      1.0  272300000.0  121050000.0   \n",
       "\n",
       "         AVTOT    ZIP  BLDFRONT  BLDDEPTH ZIP3  ZIP4  \n",
       "0    9630000.0  10004         0         0  100  1000  \n",
       "1   87210000.0  10004         0         0  100  1000  \n",
       "2   47108700.0  10004       709       564  100  1000  \n",
       "3   17640000.0  10004        85       551  100  1000  \n",
       "4  122535000.0  10004        89        57  100  1000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata['LTDEPTH']=mydata['LTDEPTH2']\n",
    "for x in [ 'median', 'count', 'widecount','widemedian', 'present', 'LTDEPTH2']:\n",
    "    del mydata[x]\n",
    "mydata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLDFRONT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d8=mydata[['TAXCLASS','ZIP','B','BLDFRONT']]\n",
    "count=d8.groupby(['ZIP','TAXCLASS']).agg({'BLDFRONT':[median_rm_na, 'count']})\n",
    "count2=d8.groupby(['B','TAXCLASS']).agg({'BLDFRONT':[median_rm_na,'count']})\n",
    "\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "mydata = mydata.merge(count, on = ['ZIP','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['B','TAXCLASS'],suffixes = ['', '_wide'])\n",
    "m=mydata['BLDFRONT'].median()\n",
    "\n",
    "mydata=mydata.rename(columns={'median_rm_na':'median','median_rm_na_wide':'widemedian','count_wide':'widecount'})\n",
    "\n",
    "\n",
    "def compare(x):\n",
    "    \n",
    "    if (x['present']==True) or (float(x['BLDFRONT'])==0):\n",
    "     #   print(2)\n",
    "        if int(x['count'])>= 20 and (not np.isnan(x['median'])):\n",
    "            return x['median']\n",
    "        elif not np.isnan(x['widemedian']):\n",
    "            return x['widemedian']\n",
    "        else:\n",
    "            return m\n",
    "    return x['BLDFRONT']\n",
    "\n",
    "mydata['present'] = mydata['BLDFRONT'].isna()\n",
    "mydata['BLDFRONT2']  = mydata.apply(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLDFRONT2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BLDFRONT2]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[np.isnan(mydata['BLDFRONT2'])][['BLDFRONT2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['BLDFRONT']=mydata['BLDFRONT2']\n",
    "for x in [ 'median', 'count', 'widemedian', 'present', 'BLDFRONT2']:\n",
    "    del mydata[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLDDEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d9=mydata[['TAXCLASS','ZIP','B','BLDDEPTH']]\n",
    "count=d9.groupby(['ZIP','TAXCLASS']).agg({'BLDDEPTH':[median_rm_na, 'count']})\n",
    "count2=d9.groupby(['B','TAXCLASS']).agg({'BLDDEPTH':[median_rm_na,'count']})\n",
    "\n",
    "count.columns=count.columns.droplevel()\n",
    "count2.columns=count2.columns.droplevel()\n",
    "mydata = mydata.merge(count, on = ['ZIP','TAXCLASS'])\n",
    "mydata = mydata.merge(count2, on = ['B','TAXCLASS'],suffixes = ['', '_wide'])\n",
    "m=mydata['BLDDEPTH'].median()\n",
    "\n",
    "mydata=mydata.rename(columns={'median_rm_na':'median','median_rm_na_wide':'widemedian','count_wide':'widecount'})\n",
    "\n",
    "\n",
    "def compare(x):\n",
    "    \n",
    "    if (x['present']==True) or (float(x['BLDDEPTH'])==0):\n",
    "     #   print(2)\n",
    "        if int(x['count'])>= 20 and (not np.isnan(x['median'])):\n",
    "            return x['median']\n",
    "        elif not np.isnan(x['widemedian']):\n",
    "            return x['widemedian']\n",
    "        else:\n",
    "            return m\n",
    "    return x['BLDDEPTH']\n",
    "\n",
    "mydata['present'] = mydata['BLDDEPTH'].isna()\n",
    "mydata['BLDDEPTH2']  = mydata.apply(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLDDEPTH2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BLDDEPTH2]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[np.isnan(mydata['BLDDEPTH2'])][['BLDDEPTH2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['BLDDEPTH']=mydata['BLDDEPTH2']\n",
    "for x in [ 'median', 'count', 'widecount','widemedian', 'present', 'BLDDEPTH2']:\n",
    "    del mydata[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identifying relevant variables based on the business understanding of the problem\n",
    "- Modifying these variables to compare them on a level footing, i.e. on a unit measure\n",
    "- Creating new variables for every field by dividing its value by aggregated value over groups of similar and relevant characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying relevant variables\n",
    "\n",
    "The problem at hand deals with identifying properties that have under or over reported the valuation of  their land for tax exemptions, and therefore the key variables of interest that determine the land's value in the dataset are:\n",
    "* FULLVAL\n",
    "* AVLAND\n",
    "* AVTOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying these relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of every property will be a function of its land area, the lot frontage outside the property. One can expect the property to have a higher value if it's based over a large area. Therefore, if these property values are directly used in our model to identify outliers, it is very much possible that the model will get incorrectly biased towards identifying larger properties as outliers.\n",
    "<br>Therefore, to scale them on a level footing, the values were modified by dividing them with relevant area metrics to calculate the valuation per unit area(sqft).\n",
    "<br>\n",
    "- r1-Value of the property per unit lot area\n",
    "- r2-Value of the property per unit building land area\n",
    "- r3-Value of the property per unit total area of the building\n",
    "- r4-Assessed value of the land per unit lot area\n",
    "- r5-Assessed value of the land per unit building land area\n",
    "- r6-Assessed value of the land per unit total area of the building\n",
    "- r7-Total assessed value of the property per unit lot area.\n",
    "- r8-Total assessed value of the property per unit building area.\n",
    "- r9-Total assessed value of the property per unit total area of the building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ratios.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new variables\n",
    "Now to compare how different these valuations over properties with similar characteristics are, the team identified certain characteristics of interest where comparisons can be made. Those of interest in the dataset being:\n",
    "1. ZIP5\n",
    "2. ZIP3\n",
    "3. TAXCLASS\n",
    "4. Borough\n",
    "5. ALL\n",
    "<br>\n",
    "\n",
    "For each property now, we calculate 45 ratios of r1-r9 with respect to the aggregated average values of r1-r9 over the five classes defined above based on where they fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df['S1'] = df['LTFRONT']* df['LTDEPTH']\n",
    "df['S2'] = df['BLDFRONT']* df['BLDDEPTH']\n",
    "df['S3'] = df['S2'] * df['STORIES']\n",
    "df['V1'] = df['FULLVAL']\n",
    "df['V2'] = df['AVLAND']\n",
    "df['V3'] = df['AVTOT']\n",
    "\n",
    "df['R1'] = df['V1']/df['S1']\n",
    "df['R2'] = df['V1']/df['S2']\n",
    "df['R3'] = df['V1']/df['S3']\n",
    "df['R4'] = df['V2']/df['S1']\n",
    "df['R5'] = df['V2']/df['S2']\n",
    "df['R6'] = df['V2']/df['S3']\n",
    "df['R7'] = df['V3']/df['S1']\n",
    "df['R8'] = df['V3']/df['S2']\n",
    "df['R9'] = df['V3']/df['S3']\n",
    "\n",
    "fraud = pd.DataFrame()\n",
    "fraud  = df[['RECORD']]\n",
    "\n",
    "fraud['REC'] = df['RECORD']\n",
    "df = df[['R1', 'R2', 'R3',\\\n",
    "       'R4', 'R5', 'R6', 'R7', 'R8', 'R9','ZIP', 'B','TAXCLASS', 'RECORD','ZIP3', 'ZIP4' ]]\n",
    "fraud = fraud.set_index(keys = 'REC')\n",
    "df = df.set_index(keys = 'RECORD')\n",
    "fraud = fraud.sort_index()\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45 new variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.groupby(by = ['ZIP']).agg({'R1':'mean', 'R2':'mean', 'R3':'mean', \\\n",
    "                             'R4':'mean', 'R5':'mean', 'R6':'mean',\\\n",
    "                             'R7':'mean', 'R8':'mean', 'R9':'mean'})\n",
    "\n",
    "a = df.merge(a, how = 'left', on = 'ZIP', suffixes = ['_x', '_y'])\n",
    "a.index = range(1,len(a)+1)\n",
    "fraud['R1Z'] = a['R1_x']/a['R1_y'] \n",
    "fraud['R2Z'] = a['R2_x']/a['R2_y'] \n",
    "fraud['R3Z'] = a['R3_x']/a['R3_y'] \n",
    "fraud['R4Z'] = a['R4_x']/a['R4_y'] \n",
    "fraud['R5Z'] = a['R5_x']/a['R5_y'] \n",
    "fraud['R6Z'] = a['R6_x']/a['R6_y'] \n",
    "fraud['R7Z'] = a['R7_x']/a['R7_y'] \n",
    "fraud['R8Z'] = a['R8_x']/a['R8_y'] \n",
    "fraud['R9Z'] = a['R9_x']/a['R9_y'] \n",
    "fraud = fraud.sort_index()\n",
    "df = df.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.groupby(by = ['B']).agg({'R1':'mean', 'R2':'mean', 'R3':'mean', \\\n",
    "                             'R4':'mean', 'R5':'mean', 'R6':'mean',\\\n",
    "                             'R7':'mean', 'R8':'mean', 'R9':'mean'})\n",
    "\n",
    "a = df.merge(a, how = 'left', on = 'B', suffixes = ['_x', '_y'])\n",
    "a.index = range(1,len(a)+1)\n",
    "\n",
    "\n",
    "fraud['R1B'] = a['R1_x']/a['R1_y'] \n",
    "fraud['R2B'] = a['R2_x']/a['R2_y'] \n",
    "fraud['R3B'] = a['R3_x']/a['R3_y'] \n",
    "fraud['R4B'] = a['R4_x']/a['R4_y'] \n",
    "fraud['R5B'] = a['R5_x']/a['R5_y'] \n",
    "fraud['R6B'] = a['R6_x']/a['R6_y'] \n",
    "fraud['R7B'] = a['R7_x']/a['R7_y'] \n",
    "fraud['R8B'] = a['R8_x']/a['R8_y'] \n",
    "fraud['R9B'] = a['R9_x']/a['R9_y'] \n",
    "\n",
    "\n",
    "fraud = fraud.sort_index()\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.groupby(by = ['TAXCLASS']).agg({'R1':'mean', 'R2':'mean', 'R3':'mean', \\\n",
    "                             'R4':'mean', 'R5':'mean', 'R6':'mean',\\\n",
    "                             'R7':'mean', 'R8':'mean', 'R9':'mean'})\n",
    "\n",
    "a = df.merge(a, how = 'left', on = 'TAXCLASS', suffixes = ['_x', '_y'])\n",
    "a.index = range(1,len(a)+1)\n",
    "\n",
    "fraud['R1T'] = a['R1_x']/a['R1_y'] \n",
    "fraud['R2T'] = a['R2_x']/a['R2_y'] \n",
    "fraud['R3T'] = a['R3_x']/a['R3_y'] \n",
    "fraud['R4T'] = a['R4_x']/a['R4_y'] \n",
    "fraud['R5T'] = a['R5_x']/a['R5_y'] \n",
    "fraud['R6T'] = a['R6_x']/a['R6_y'] \n",
    "fraud['R7T'] = a['R7_x']/a['R7_y'] \n",
    "fraud['R8T'] = a['R8_x']/a['R8_y'] \n",
    "fraud['R9T'] = a['R9_x']/a['R9_y'] \n",
    "\n",
    "\n",
    "fraud = fraud.sort_index()\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP3\n",
    "a = df.groupby(by = ['ZIP3']).agg({'R1':'mean', 'R2':'mean', 'R3':'mean', \\\n",
    "                             'R4':'mean', 'R5':'mean', 'R6':'mean',\\\n",
    "                             'R7':'mean', 'R8':'mean', 'R9':'mean'})\n",
    "\n",
    "a = df.merge(a, how = 'left', on = 'ZIP3', suffixes = ['_x', '_y'])\n",
    "a.index = range(1,len(a)+1)\n",
    "\n",
    "\n",
    "fraud['R1Z3'] = a['R1_x']/a['R1_y'] \n",
    "fraud['R2Z3'] = a['R2_x']/a['R2_y'] \n",
    "fraud['R3Z3'] = a['R3_x']/a['R3_y'] \n",
    "fraud['R4Z3'] = a['R4_x']/a['R4_y'] \n",
    "fraud['R5Z3'] = a['R5_x']/a['R5_y'] \n",
    "fraud['R6Z3'] = a['R6_x']/a['R6_y'] \n",
    "fraud['R7Z3'] = a['R7_x']/a['R7_y'] \n",
    "fraud['R8Z3'] = a['R8_x']/a['R8_y'] \n",
    "fraud['R9Z3'] = a['R9_x']/a['R9_y'] \n",
    "\n",
    "\n",
    "fraud = fraud.sort_index()\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all\n",
    "\n",
    "fraud['R1A'] = df['R1']/np.mean(df['R1'])\n",
    "\n",
    "fraud['R2A'] = df['R2']/np.mean(df['R2'])\n",
    "fraud['R3A'] = df['R3']/np.mean(df['R3'])\n",
    "fraud['R4A'] = df['R4']/np.mean(df['R4'])\n",
    "fraud['R5A'] = df['R5']/np.mean(df['R5'])\n",
    "\n",
    "fraud['R6A'] = df['R6']/np.mean(df['R6'])\n",
    "fraud['R7A'] = df['R7']/np.mean(df['R7'])\n",
    "fraud['R8A'] = df['R8']/np.mean(df['R8'])\n",
    "\n",
    "fraud['R9A'] = df['R9']/np.mean(df['R9'])\n",
    "\n",
    "fraud = fraud.sort_index()\n",
    "df = df.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=fraud.copy()\n",
    "a = x.columns[0]\n",
    "del x['RECORD']\n",
    "del fraud['RECORD']\n",
    "fraud=preprocessing.scale(fraud)\n",
    "pca=PCA(n_components=8,copy=False)   # After plot the number of components and variance line chart, 8 is good\n",
    "fraud=pca.fit_transform(fraud)#pca  \n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud=pd.DataFrame(preprocessing.scale(fraud),columns = ['component1', 'component2', 'component3', \n",
    "                                                             'component4', 'component5', 'component6', \n",
    "                                                             'component7', 'component8'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component1</th>\n",
       "      <th>component2</th>\n",
       "      <th>component3</th>\n",
       "      <th>component4</th>\n",
       "      <th>component5</th>\n",
       "      <th>component6</th>\n",
       "      <th>component7</th>\n",
       "      <th>component8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.018969</td>\n",
       "      <td>-0.094106</td>\n",
       "      <td>-0.074198</td>\n",
       "      <td>-0.029343</td>\n",
       "      <td>0.114940</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>-0.112318</td>\n",
       "      <td>-0.056423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.268693</td>\n",
       "      <td>16.572698</td>\n",
       "      <td>5.318490</td>\n",
       "      <td>-4.170378</td>\n",
       "      <td>-4.566852</td>\n",
       "      <td>4.891739</td>\n",
       "      <td>10.514436</td>\n",
       "      <td>-1.459022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002922</td>\n",
       "      <td>0.079073</td>\n",
       "      <td>-0.013284</td>\n",
       "      <td>0.086232</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.025630</td>\n",
       "      <td>-0.107896</td>\n",
       "      <td>0.057943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075090</td>\n",
       "      <td>-0.073002</td>\n",
       "      <td>-0.055368</td>\n",
       "      <td>0.012855</td>\n",
       "      <td>0.027145</td>\n",
       "      <td>-0.184669</td>\n",
       "      <td>-0.050301</td>\n",
       "      <td>0.126573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.300791</td>\n",
       "      <td>-3.037439</td>\n",
       "      <td>-0.180367</td>\n",
       "      <td>-0.332434</td>\n",
       "      <td>-9.695408</td>\n",
       "      <td>-29.156924</td>\n",
       "      <td>9.289344</td>\n",
       "      <td>19.390790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   component1  component2  component3  component4  component5  component6  \\\n",
       "0   -0.018969   -0.094106   -0.074198   -0.029343    0.114940    0.021636   \n",
       "1    2.268693   16.572698    5.318490   -4.170378   -4.566852    4.891739   \n",
       "2   -0.002922    0.079073   -0.013284    0.086232    0.021255    0.025630   \n",
       "3    0.075090   -0.073002   -0.055368    0.012855    0.027145   -0.184669   \n",
       "4   13.300791   -3.037439   -0.180367   -0.332434   -9.695408  -29.156924   \n",
       "\n",
       "   component7  component8  \n",
       "0   -0.112318   -0.056423  \n",
       "1   10.514436   -1.459022  \n",
       "2   -0.107896    0.057943  \n",
       "3   -0.050301    0.126573  \n",
       "4    9.289344   19.390790  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = fraud.columns\n",
    "fraud_backup = fraud.copy()\n",
    "for i in cols:\n",
    "    fraud[i] = fraud[i].apply(lambda x: x**2)\n",
    "\n",
    "fraud['score']  = fraud.sum(axis = 1)\n",
    "fraud['score'] = fraud['score'].apply(lambda x: x**0.5)\n",
    "hello = fraud[['score']]\n",
    "fraud = fraud_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9902 - acc: 0.3521\n",
      "Epoch 2/10\n",
      " 129024/1070994 [==>...........................] - ETA: 1s - loss: 1.4540 - acc: 0.3493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.9365 - acc: 0.3453\n",
      "Epoch 3/10\n",
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.8949 - acc: 0.3514\n",
      "Epoch 4/10\n",
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.8576 - acc: 0.3787\n",
      "Epoch 5/10\n",
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.8354 - acc: 0.3798\n",
      "Epoch 6/10\n",
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.8205 - acc: 0.3607\n",
      "Epoch 7/10\n",
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.8071 - acc: 0.3444\n",
      "Epoch 8/10\n",
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.7939 - acc: 0.3365\n",
      "Epoch 9/10\n",
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.7828 - acc: 0.3379\n",
      "Epoch 10/10\n",
      "1070994/1070994 [==============================] - 1s 1us/step - loss: 0.7688 - acc: 0.3328\n"
     ]
    }
   ],
   "source": [
    "## autoencoder model  --- takes time to run\n",
    "components_train = fraud.values\n",
    "\n",
    "input_dim = fraud.shape[1]\n",
    "encoding_dim = 8\n",
    "\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "#encoder = Dense(encoding_dim, activation=\"elu\", \n",
    "#               activity_regularizer=regularizers.l1(10e-5))(input_layer)    # for classification variables\n",
    "\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(input_layer)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='elu')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "\n",
    "nb_epoch = 10\n",
    "batch_size = 1024\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "history = autoencoder.fit(components_train, components_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                   # validation_data=(X_test, X_test),\n",
    "                    verbose=1,\n",
    "                   callbacks=[checkpointer, tensorboard]\n",
    "                    ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.89687140e-02, -9.41063287e-02, -7.41981491e-02, ...,\n",
       "         2.16357537e-02, -1.12317902e-01, -5.64226292e-02],\n",
       "       [ 2.26869289e+00,  1.65726980e+01,  5.31849009e+00, ...,\n",
       "         4.89173896e+00,  1.05144361e+01, -1.45902231e+00],\n",
       "       [-2.92216294e-03,  7.90728026e-02, -1.32838306e-02, ...,\n",
       "         2.56295260e-02, -1.07896275e-01,  5.79433263e-02],\n",
       "       ...,\n",
       "       [-2.66936603e-02, -1.05955413e-01, -8.35575997e-03, ...,\n",
       "        -1.10786274e-02, -1.22804235e-01,  5.32574743e-02],\n",
       "       [-1.73046136e-02, -8.92742593e-02, -5.42809405e-03, ...,\n",
       "        -9.81328516e-03, -1.05260673e-01,  6.18442107e-02],\n",
       "       [-2.01080477e-02, -6.19584967e-02,  8.13475921e-03, ...,\n",
       "         8.70429782e-03, -7.39934999e-02,  5.66006494e-02]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 1.1329055e-02],\n",
       "       [0.0000000e+00, 1.5581633e+01, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 7.3858440e-02, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 6.7619056e-02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 5.9738338e-02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 1.2935460e-02]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = autoencoder.predict(components_train)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = pd.DataFrame.from_records(predictions, columns = ['component1', 'component2', 'component3', \n",
    "                                                             'component4', 'component5', 'component6', \n",
    "                                                             'component7', 'component8'] ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
